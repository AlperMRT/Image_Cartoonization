{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446c311c-3626-4e54-b410-308758a59f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def cartoonize_bilateral(img: np.ndarray,\n",
    "                         d: int, sigmaColor: int, sigmaSpace: int,\n",
    "                         low: int, high: int, median_k: int) -> np.ndarray:\n",
    "    \"\"\"Traditional cartoonize process using Bilateral filter and Canny.\"\"\"\n",
    "    \n",
    "    # Apply Bilateral Filter for smoothing while preserving edges.\n",
    "    sm = cv2.bilateralFilter(img, d, sigmaColor, sigmaSpace)\n",
    "    \n",
    "    # Convert image to grayscale for Canny edge detection.\n",
    "    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Median Blur to reduce noise before edge detection.\n",
    "    g = cv2.medianBlur(g, median_k)\n",
    "    \n",
    "    # Detect edges using Canny.\n",
    "    edges = cv2.Canny(g, low, high)\n",
    "    \n",
    "    # Invert the edge map (black edges on white background).\n",
    "    inv = cv2.bitwise_not(edges)\n",
    "    \n",
    "    # Convert the inverted edge map back to 3 channels for merging.\n",
    "    invc = cv2.cvtColor(inv, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Combine the smoothed image with the edge mask.\n",
    "    return cv2.bitwise_and(sm, invc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7c0bb7-ed01-4a5e-b172-a74d8a74a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def cartoonize_guided_kmeans(img: np.ndarray,\n",
    "                             radius: int = 7, eps: int = 500, k: int = 16,\n",
    "                             median_k: int = 5, low: int = 80, high: int = 220) -> np.ndarray:\n",
    "    \"\"\"Cartoonize process using Guided Filter and K-Means.\"\"\"\n",
    "\n",
    "    # 1. Edge Detection\n",
    "    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    g = cv2.medianBlur(g, median_k)\n",
    "    edges = cv2.Canny(g, low, high)\n",
    "    edges_inverted = cv2.bitwise_not(edges)\n",
    "    edges_bgr = cv2.cvtColor(edges_inverted, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 2. Guided Filter\n",
    "    # Check if opencv-contrib-python is installed\n",
    "    if not hasattr(cv2, 'ximgproc'):\n",
    "        raise ImportError(\"opencv-contrib-python is not installed. Install it with 'pip install opencv-contrib-python'.\")\n",
    "    image_guided = cv2.ximgproc.guidedFilter(img, img, radius, eps)\n",
    "\n",
    "    # 3. K-Means Clustering for Color Quantization\n",
    "    # Reshape the image to be a list of pixels\n",
    "    pixels = image_guided.reshape((-1, 3))\n",
    "    pixels = np.float32(pixels)\n",
    "\n",
    "    # Define criteria, number of clusters(k) and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    attempts = 10\n",
    "    compactness, labels, centers = cv2.kmeans(pixels, k, None, criteria, attempts, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Convert back to uint8 and make the original image\n",
    "    centers = np.uint8(centers)\n",
    "    image_kmeans = centers[labels.flatten()]\n",
    "    image_kmeans = image_kmeans.reshape(img.shape)\n",
    "\n",
    "    # 4. Combination\n",
    "    # Combine the K-Means image with the edge mask\n",
    "    return cv2.bitwise_and(image_kmeans, edges_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e61abe-a86c-4a0a-b87b-1e2da295f5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: ['1.jpg', '2.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg', '9.jpg', '10.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg', '20.jpg', '21.jpg', '22.jpg', '23.jpg', '24.jpg', '25.jpg', '26.jpg', '27.jpg', '28.jpg', '29.jpg', '30.jpg', '31.jpg', '32.jpg', '33.jpg', '34.jpg', '35.jpg', '36.jpg', '37.jpg', '38.jpg', '39.jpg', '40.jpg']\n",
      "Processing: 1.jpg...\n",
      "  -> Completed: 1.jpg\n",
      "Processing: 2.jpg...\n",
      "  -> Completed: 2.jpg\n",
      "Processing: 3.jpg...\n",
      "  -> Completed: 3.jpg\n",
      "Processing: 4.jpg...\n",
      "  -> Completed: 4.jpg\n",
      "Processing: 5.jpg...\n",
      "  -> Completed: 5.jpg\n",
      "Processing: 6.jpg...\n",
      "  -> Completed: 6.jpg\n",
      "Processing: 7.jpg...\n",
      "  -> Completed: 7.jpg\n",
      "Processing: 8.jpg...\n",
      "  -> Completed: 8.jpg\n",
      "Processing: 9.jpg...\n",
      "  -> Completed: 9.jpg\n",
      "Processing: 10.jpg...\n",
      "  -> Completed: 10.jpg\n",
      "Processing: 11.jpg...\n",
      "  -> Completed: 11.jpg\n",
      "Processing: 12.jpg...\n",
      "  -> Completed: 12.jpg\n",
      "Processing: 13.jpg...\n",
      "  -> Completed: 13.jpg\n",
      "Processing: 14.jpg...\n",
      "  -> Completed: 14.jpg\n",
      "Processing: 15.jpg...\n",
      "  -> Completed: 15.jpg\n",
      "Processing: 16.jpg...\n",
      "  -> Completed: 16.jpg\n",
      "Processing: 17.jpg...\n",
      "  -> Completed: 17.jpg\n",
      "Processing: 18.jpg...\n",
      "  -> Completed: 18.jpg\n",
      "Processing: 19.jpg...\n",
      "  -> Completed: 19.jpg\n",
      "Processing: 20.jpg...\n",
      "  -> Completed: 20.jpg\n",
      "Processing: 21.jpg...\n",
      "  -> Completed: 21.jpg\n",
      "Processing: 22.jpg...\n",
      "  -> Completed: 22.jpg\n",
      "Processing: 23.jpg...\n",
      "  -> Completed: 23.jpg\n",
      "Processing: 24.jpg...\n",
      "  -> Completed: 24.jpg\n",
      "Processing: 25.jpg...\n",
      "  -> Completed: 25.jpg\n",
      "Processing: 26.jpg...\n",
      "  -> Completed: 26.jpg\n",
      "Processing: 27.jpg...\n",
      "  -> Completed: 27.jpg\n",
      "Processing: 28.jpg...\n",
      "  -> Completed: 28.jpg\n",
      "Processing: 29.jpg...\n",
      "  -> Completed: 29.jpg\n",
      "Processing: 30.jpg...\n",
      "  -> Completed: 30.jpg\n",
      "Processing: 31.jpg...\n",
      "  -> Completed: 31.jpg\n",
      "Processing: 32.jpg...\n",
      "  -> Completed: 32.jpg\n",
      "Processing: 33.jpg...\n",
      "  -> Completed: 33.jpg\n",
      "Processing: 34.jpg...\n",
      "  -> Completed: 34.jpg\n",
      "Processing: 35.jpg...\n",
      "  -> Completed: 35.jpg\n",
      "Processing: 36.jpg...\n",
      "  -> Completed: 36.jpg\n",
      "Processing: 37.jpg...\n",
      "  -> Completed: 37.jpg\n",
      "Processing: 38.jpg...\n",
      "  -> Completed: 38.jpg\n",
      "Processing: 39.jpg...\n",
      "  -> Completed: 39.jpg\n",
      "Processing: 40.jpg...\n",
      "  -> Completed: 40.jpg\n",
      "\n",
      "All processing completed! Results saved to 'output_bilateral_40' and 'output_guided_40' folders.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ==============================================================================\n",
    "# == FUNCTIONS ==\n",
    "# ==============================================================================\n",
    "\n",
    "def cartoonize_bilateral(img: np.ndarray,\n",
    "                         d: int, sigmaColor: int, sigmaSpace: int,\n",
    "                         low: int, high: int, median_k: int) -> np.ndarray:\n",
    "    \"\"\"Traditional cartoonize process using Bilateral filter and Canny.\"\"\"\n",
    "    # Apply Bilateral Filter for smoothing while preserving edges.\n",
    "    sm = cv2.bilateralFilter(img, d, sigmaColor, sigmaSpace)\n",
    "    # Convert image to grayscale for Canny edge detection.\n",
    "    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Median Blur to reduce noise before edge detection.\n",
    "    g = cv2.medianBlur(g, median_k)\n",
    "    # Detect edges using Canny.\n",
    "    edges = cv2.Canny(g, low, high)\n",
    "    # Invert the edge map (black edges on white background).\n",
    "    inv = cv2.bitwise_not(edges)\n",
    "    # Convert the inverted edge map back to 3 channels for merging.\n",
    "    invc = cv2.cvtColor(inv, cv2.COLOR_GRAY2BGR)\n",
    "    # Combine the smoothed image with the edge mask.\n",
    "    return cv2.bitwise_and(sm, invc)\n",
    "\n",
    "def cartoonize_guided_kmeans(img: np.ndarray,\n",
    "                             radius: int = 7, eps: int = 500, k: int = 16,\n",
    "                             median_k: int = 5, low: int = 80, high: int = 220) -> np.ndarray:\n",
    "    \"\"\"Cartoonize process using Guided Filter and K-Means.\"\"\"\n",
    "    # 1. Edge Detection\n",
    "    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    g = cv2.medianBlur(g, median_k)\n",
    "    edges = cv2.Canny(g, low, high)\n",
    "    edges_inverted = cv2.bitwise_not(edges)\n",
    "    edges_bgr = cv2.cvtColor(edges_inverted, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # 2. Guided Filter\n",
    "    # Check if opencv-contrib-python is installed\n",
    "    if not hasattr(cv2, 'ximgproc'):\n",
    "        raise ImportError(\"opencv-contrib-python is not installed. Install it with 'pip install opencv-contrib-python'.\")\n",
    "    image_guided = cv2.ximgproc.guidedFilter(img, img, radius, eps)\n",
    "\n",
    "    # 3. K-Means Clustering\n",
    "    pixels = image_guided.reshape((-1, 3))\n",
    "    pixels = np.float32(pixels)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    attempts = 10\n",
    "    compactness, labels, centers = cv2.kmeans(pixels, k, None, criteria, attempts, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    image_kmeans = centers[labels.flatten()]\n",
    "    image_kmeans = image_kmeans.reshape(img.shape)\n",
    "\n",
    "    # 4. Combination\n",
    "    return cv2.bitwise_and(image_kmeans, edges_bgr)\n",
    "\n",
    "# ==============================================================================\n",
    "# == BATCH PROCESSING ==\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Define Paths (Assuming 'photo_40' is in the same directory as the notebook)\n",
    "input_folder = Path(\"photo_40\")  # Updated input folder for 40 photos\n",
    "output_bilateral_folder = Path(\"output_bilateral_40\") # New output folder\n",
    "output_guided_folder = Path(\"output_guided_40\")       # New output folder\n",
    "\n",
    "# 2. Create Output Directories\n",
    "output_bilateral_folder.mkdir(exist_ok=True)\n",
    "output_guided_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# 3. Define Parameters\n",
    "bilateral_params_v10 = {\"d\": 5, \"sigmaColor\": 100, \"sigmaSpace\": 100,\n",
    "                        \"low\": 80, \"high\": 220, \"median_k\": 5}\n",
    "guided_params_k16 = {\"radius\": 7, \"eps\": 500, \"k\": 16, # Added k=16 explicitly\n",
    "                     \"median_k\": 5, \"low\": 80, \"high\": 220}\n",
    "\n",
    "# 4. Process Photos\n",
    "# Get only .jpg files\n",
    "image_files = list(input_folder.glob(\"*.jpg\"))\n",
    "\n",
    "# Optional: Sort files numerically if needed (handles 1.jpg, 10.jpg correctly)\n",
    "def get_number(file_path):\n",
    "    try:\n",
    "        return int(os.path.splitext(file_path.name)[0])\n",
    "    except ValueError:\n",
    "        return -1 # Handle cases where filename is not a number\n",
    "\n",
    "image_files = sorted(image_files, key=get_number)\n",
    "\n",
    "print(f\"Found files: {[f.name for f in image_files]}\") # Check found files\n",
    "\n",
    "for img_path in image_files:\n",
    "    print(f\"Processing: {img_path.name}...\")\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        print(f\"  -> ERROR: Could not read {img_path.name}.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Apply and Save Bilateral\n",
    "        out_bilateral = cartoonize_bilateral(img, **bilateral_params_v10)\n",
    "        save_path_b = output_bilateral_folder / f\"{img_path.stem}_bilateral.png\"\n",
    "        cv2.imwrite(str(save_path_b), out_bilateral)\n",
    "\n",
    "        # Apply and Save Guided+KMeans (k=16)\n",
    "        out_guided = cartoonize_guided_kmeans(img, **guided_params_k16)\n",
    "        save_path_g = output_guided_folder / f\"{img_path.stem}_guided_k16.png\" # Updated save name\n",
    "        cv2.imwrite(str(save_path_g), out_guided)\n",
    "\n",
    "        print(f\"  -> Completed: {img_path.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  -> ERROR: An error occurred while processing {img_path.name}: {e}\")\n",
    "\n",
    "print(\"\\nAll processing completed! Results saved to 'output_bilateral_40' and 'output_guided_40' folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283eb9ac-a6a2-4f4b-9bfe-859d8052e116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
